{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tensorflow数据读取机制中内存队列，文件名队列详解见[十图详解tensorflow数据读取机制](https://zhuanlan.zhihu.com/p/27238630)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多线程与queue（内存队列）\n",
    "Tensorflow中提供了FIFOQueue和RandomShuffleQueue两种内存队列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "1\n",
      "11\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# 创建一个先进先出队列，指定队列中最多可以保存两个元素，并指定类型\n",
    "q = tf.FIFOQueue(2, dtypes='int32')\n",
    "\n",
    "# 创建一个随机队列，它会将队列中元素打乱，每次出队操作得到的是从当前队列\n",
    "# 所有元素中随机挑选的一个，必须传入min_after_dequeue（队列中最少元素个数）参数\n",
    "# q = tf.RandomShuffleQueue(2, min_after_dequeue=0, dtypes='int32')\n",
    "\n",
    "# 使用enqueue_many初始化函数，使用队列之前必须明确调用初始化\n",
    "init = q.enqueue_many(([0, 10], ))\n",
    "\n",
    "# 使用dequeue函数出队\n",
    "x = q.dequeue()\n",
    "\n",
    "y = x + 1\n",
    "\n",
    "# 重新入队\n",
    "q_inc = q.enqueue([y])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 运行初始化队列操作\n",
    "    init.run()\n",
    "    for _ in range(5):\n",
    "        v, _  = sess.run([x, q_inc])\n",
    "        print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow提供了**tf.Coordinator**和**tf.QueueRunner**两个类来完成多线程协同的功能。**tf.Coordinator**主要用于协同多个线程一起停止，并提供了**should_stop**，**request_stop**和**join**三个函数。\n",
    "\n",
    "启动线程之前，需要声明一个`tf.Coordinator`类，并将这个类传入每一个创建的建成中。启动的线程需要一直查询`tf.Coordinator`类中提供的`should_stop`函数，当这个函数的返回值为True时，当前线程退出。每一个启动的线程都可以通过调用`request_stop`函数通知其他线程退出。\n",
    "\n",
    "当一个线程调用`request_stop`函数后，`should_stop`函数的返回值被设置为True。这样其他线程就可以同时终止。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on id: 0\n",
      "Working on id: 1\n",
      "Working on id: 2\n",
      "\n",
      "\n",
      "\n",
      "Working on id: 3\n",
      "\n",
      "Working on id: 4\n",
      "\n",
      "Working on id: 0\n",
      "\n",
      "Working on id: 1\n",
      "\n",
      "Working on id: 2\n",
      "\n",
      "Working on id: 3\n",
      "\n",
      "Working on id: 4\n",
      "\n",
      "Working on id: 0\n",
      "\n",
      "Working on id: 1\n",
      "\n",
      "Working on id: 2\n",
      "\n",
      "Stoping from id: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "\n",
    "# 线程中运行的程序，该程序每隔1s判断是否需要停止并打印自己的ID\n",
    "def my_loop(coord, worker_id):\n",
    "    # 使用tf.Coordinator类提供的协同工具判断当前线程是否需要停止\n",
    "    while not coord.should_stop():\n",
    "        # 随机停止所有线程\n",
    "        if(np.random.rand() < 0.1):\n",
    "            print('Stoping from id: %d\\n' % worker_id)\n",
    "            # 调用coord.request_stop()通知其他线程停止\n",
    "            coord.request_stop()\n",
    "        else:\n",
    "            # 打印当前线程id\n",
    "            print('Working on id: %d\\n' % worker_id)\n",
    "        time.sleep(1)\n",
    "        \n",
    "# 声明一个tf.train.Coordinator类协同多个线程\n",
    "coord = tf.train.Coordinator()\n",
    "# 创建5个线程\n",
    "threads = [threading.Thread(target=my_loop, args=(coord, i)) for i in range(5)]\n",
    "# 启动所有线程\n",
    "for t in threads:\n",
    "    t.start()\n",
    "\n",
    "# 等待所有线程退出\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf.QueueRunner**用于启动多个线程操作同一个队列，启动的这些线程可以通过`tf.Coordinator`统一管理。\n",
    "\n",
    "以下程序利用多线程将随机数入队，单线程出队打印。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.480941\n",
      "0.834668\n",
      "-1.05499\n",
      "-1.0778\n",
      "-1.31522\n",
      "0.102408\n",
      "-0.166196\n",
      "-1.63906\n",
      "0.400012\n",
      "-0.207954\n",
      "0.814503\n",
      "1.36503\n",
      "0.305135\n",
      "1.4215\n",
      "1.58674\n",
      "-0.802489\n",
      "1.56601\n",
      "-0.0561557\n",
      "0.591244\n",
      "-0.826584\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "queue = tf.FIFOQueue(100, 'float')\n",
    "# 定义队列的入队操作，tf.random_normal()从正态分布输出随机值\n",
    "enqueue_op = queue.enqueue([tf.random_normal([1])])\n",
    "\n",
    "# 创建多个线程运行队列的入队操作，queue是被操作的队列，[enqueue_op] * 5表示启动5个\n",
    "# 线程，每个线程中运行的是enqueue_op操作\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * 5)\n",
    "\n",
    "# 将定义过的QueueRunner加入Tensorflow计算图上指定的集合\n",
    "# tf.train.add_queue_runner函数没有指定集合\n",
    "# 则加入默认集合tf.GraphKeys.QUEUE_RUNNERS\n",
    "tf.train.add_queue_runner(qr)\n",
    "# 定义出队操作\n",
    "out_tensor = queue.dequeue()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # 使用tf.train.Coordinator协同启动的线程\n",
    "    coord = tf.train.Coordinator()\n",
    "    # 使用tf.train.QueueRunner时，需要明确调用tf.train.start_queue_runners\n",
    "    # 启动所有线程。tf.train.start_queue_runners函数默认启动tf.GraphKeys.QUEUE_RUNNERS\n",
    "    # 集合中所有的QueueRunner。\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    # 获取队列中的取值\n",
    "    for _ in range(20):\n",
    "        print(sess.run(out_tensor)[0])\n",
    "    \n",
    "    # 读取完值后，使用tf.train.Coordinator停止所有线程\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入文件名队列\n",
    "**tf.train.string_input_producer**函数会使用初始化时提供的文件列表创建一个**文件名队列**。\n",
    "\n",
    "通过设置**shuffle**参数，可以打乱文件名队列中的顺序。当`shuffle`参数为True时，文件在加入文件名队列之前就会被打乱顺序。`tf.train.string_input_producer`生成的文件名队列可以同时被多个文件读取线程操作，而且会将队列中的文件均匀地分给不同线程。\n",
    "\n",
    "通过设置**num_epochs**参数限制文件名队列加载文件列表的最大轮数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "data_path = os.path.join('.', 'data')\n",
    "if(not os.path.exists(data_path)):\n",
    "    os.mkdir(data_path)\n",
    "\n",
    "# 模拟海量数据情况下将数据写入不同的文件。num_shards定义了总共写入多少个TFRecords文件。\n",
    "# instatnces_per_shard定义了每个TFRcords文件中有多少个数据。\n",
    "num_shards = 2\n",
    "instances_per_shard = 2\n",
    "\n",
    "for i in range(num_shards):\n",
    "    # 将数据分为多个文件时，可以将不同文件以类似0000n-of-0000m的前缀区分，m表示TFRecords数据\n",
    "    # 总个数（2个），n表示第几个TFRecords数据\n",
    "    filename = os.path.join(data_path, 'data_000%d_of_000%d.tfrecords' % (i, num_shards))\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    # 将数据封装为Example结构写入TFRecord文件\n",
    "    for j in range(instances_per_shard):\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'i': tf.train.Feature(int64_list=tf.train.Int64List(value=[i])),\n",
    "            'j': tf.train.Feature(int64_list=tf.train.Int64List(value=[j]))\n",
    "        }))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`tf.train.match_filenames_once`和`tf.train.string_input_producer`读取TFRecrods中的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'matching_filenames:0' shape=<unknown> dtype=string_ref>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "data_path = os.path.join('.', 'data')\n",
    "\n",
    "filenames = tf.train.match_filenames_once(os.path.join(data_path, '*'))\n",
    "\n",
    "print(filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
